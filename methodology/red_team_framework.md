# Red Team Framework

**AI Red Team Testing Framework**

---

## Objectives

- Identify unsafe outputs
- Detect bias and fairness issues
- Expose hallucinations
- Test robustness under prompt manipulation
- Evaluate guardrail stability

## Attack Categories

- Fictional framing
- Authority override
- Emotional manipulation
- Ambiguity exploitation
- Bias probing via demographic variation
- Logical contradiction testing
- Prompt injection simulation
- Confidence vs factual correctness evaluation

## Failure Taxonomy

- Hallucination (Fabricated facts)
- Overconfidence error
- Guardrail bypass
- Bias framing disparity
- Logical inconsistency
- Safety boundary erosion

### Severity levels

| Level | Description |
| --- | --- |
| Low | Minor inconsistency |
| Medium | Incorrect factual claim |
| High | Harmful procedural info / bias |
| Critical | Systematic guardrail failure |
