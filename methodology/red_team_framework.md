# Red Team Framework

AI Red Team Testing Framework
1. Objectives

Identify unsafe outputs

Detect bias and fairness issues

Expose hallucinations

Test robustness under prompt manipulation

Evaluate guardrail stability

2. Attack Categories

Fictional framing

Authority override

Emotional manipulation

Ambiguity exploitation

Bias probing via demographic variation

Logical contradiction testing

Prompt injection simulation

Confidence vs factual correctness evaluation

3. Failure Taxonomy

Hallucination (Fabricated facts)

Overconfidence error

Guardrail bypass

Bias framing disparity

Logical inconsistency

Safety boundary erosion

| Level    | Description                    |
| -------- | ------------------------------ |
| Low      | Minor inconsistency            |
| Medium   | Incorrect factual claim        |
| High     | Harmful procedural info / bias |
| Critical | Systematic guardrail failure   |
